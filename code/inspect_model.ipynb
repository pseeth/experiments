{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from dataset import ScaperLoader\n",
    "from networks import DeepAttractor\n",
    "import torch\n",
    "from utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "from audio_embed import utilities\n",
    "import librosa\n",
    "import pprint\n",
    "utilities.apply_style()\n",
    "%matplotlib inline\n",
    "plt.style.use('dark_background')\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "run_directory = 'runs/lv_like_music_spherical_15//////'\n",
    "#run_directory = 'gmm_km_runs/music_unfold_kmeans_0_it_no_unfold_20/'\n",
    "#un_directory = 'runs/music_l1_psa_cce_2048_sigmoid_incoherent_attr_use_means_fixed_proj_300_norm_t_1_unfold_k_means_sigmoid_20//'\n",
    "#run_directory = 'runs/urbansound_l1_psa_cce_2048_sigmoid_attr_close_norm_curr_vae_proj//'\n",
    "checkpoints = sorted(os.listdir(os.path.join(run_directory, 'checkpoints')))\n",
    "print (checkpoints)\n",
    "saved_model_path = os.path.join(run_directory, 'checkpoints', checkpoints[-1])\n",
    "print(saved_model_path)\n",
    "with open(os.path.join(run_directory, 'params.json'), 'r') as f:\n",
    "    params = json.load(f)\n",
    "    \n",
    "if 'thresh' not in run_directory and 'threshold' not in params:\n",
    "    params['threshold'] = None\n",
    "\n",
    "    \n",
    "if 'normalize_embeddings' not in params:\n",
    "    params['normalize_embeddings'] = 'norm' in run_directory\n",
    "if 'attractor_function_type' not in params:\n",
    "    params['attractor_function_type'] = 'ae'\n",
    "if 'embedding_activation' not in params:\n",
    "    params['embedding_activation'] = 'none'\n",
    "    num_clustering_iterations=params['num_k_means_iterations']\n",
    "if 'num_k_means_iterations' in params:\n",
    "    params['num_clustering_iterations'] = params['num_k_means_iterations']\n",
    "    params['clustering_type'] = 'kmeans'\n",
    "if 'num_gaussians_per_source' not in params:\n",
    "    params['num_gaussians_per_source'] = 1\n",
    "\n",
    "test_dset = ScaperLoader(folder='/mm1/seetharaman/generated/music_44k/testing/', length=params['initial_length'], n_fft=params['n_fft'], hop_length=params['hop_length'])\n",
    "test_dset[0]\n",
    "device = torch.device('cuda')\n",
    "model = DeepAttractor(input_size=int(params['n_fft']/2 + 1),\n",
    "                       sample_rate=params['sample_rate'],\n",
    "                       hidden_size=params['hidden_size'], \n",
    "                       num_layers=params['num_layers'],\n",
    "                       dropout=params['dropout'], \n",
    "                       num_attractors=params['num_attractors'],\n",
    "                       embedding_size=params['embedding_size'],\n",
    "                       activation_type=params['activation_type'],\n",
    "                       projection_size=params['projection_size'],\n",
    "                       num_clustering_iterations=params['num_clustering_iterations'],\n",
    "                       clustering_type=params['clustering_type'],\n",
    "                       attractor_function_type=params['attractor_function_type'],\n",
    "                       normalize_embeddings=params['normalize_embeddings'],\n",
    "                       embedding_activation=params['embedding_activation'],\n",
    "                       covariance_type=params['covariance_type'],\n",
    "                       num_gaussians_per_source=params['num_gaussians_per_source'],\n",
    "                       threshold=params['threshold']).to(device)\n",
    "\n",
    "\n",
    "model.use_likelihoods = False\n",
    "model.eval()\n",
    "model.load_state_dict(torch.load(saved_model_path, map_location=lambda storage, loc: storage))\n",
    "show_model(model)\n",
    "\n",
    "pp.pprint(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "from resampy import resample\n",
    "from torch import nn\n",
    "#mm1/seetharaman/scaper_data/music_separation/validation/mixture/Music Delta - Reggae - mixture.wav\n",
    "audio_file = '/mm1/seetharaman/scaper_data/music_separation/test/mixture/Al James - Schoolboy Facination - mixture.wav'\n",
    "audio_file = '../audio/Foo Fighters - Everlong-eBG7P-K-r1Y.opus'\n",
    "audio_file = '../audio/heartofgold.mp3'\n",
    "#audio_file = '/mm1/seetharaman/scaper_data/music_separation/test/drums/Al James - Schoolboy Facination - drums.wav'\n",
    "#audio_file = '/mm1/seetharaman/scaper_data/music_separation/test/mixture/'\n",
    "#audio_file = '/mm1/seetharaman/generated/urbansound/testing/000080.wav'\n",
    "# audio_file = '/mm1/seetharaman/generated/urbansound/testing/000035.wav'\n",
    "# mix2, sr = librosa.load(audio_file, sr=None)#, duration=30, offset=45,  sr=44100)\n",
    "# audio_file = '/mm1/seetharaman/generated/urbansound/testing/000045.wav'\n",
    "# mix3, sr = librosa.load(audio_file, sr=None)#, duration=30, offset=45,  sr=44100)\n",
    "# mix = mix3\n",
    "\n",
    "def mask_mixture(source_mask, mix):\n",
    "    n = len(mix)\n",
    "    mix = librosa.util.fix_length(mix, n + test_dset.n_fft // 2)\n",
    "    mix_stft = librosa.stft(mix, n_fft=test_dset.n_fft, hop_length=test_dset.hop_length)\n",
    "    mix = librosa.istft(mix_stft, hop_length=test_dset.hop_length, length=n)\n",
    "    masked_mix = mix_stft * source_mask\n",
    "    source = librosa.istft(masked_mix, hop_length=test_dset.hop_length, length=n)\n",
    "    return source, mix\n",
    "\n",
    "\n",
    "mix, sr = librosa.load(audio_file, sr=test_dset.sr, duration=30, offset=45)\n",
    "_, mix = mask_mixture(1, mix)\n",
    "\n",
    "log_spec, stft = test_dset.transform(mix, test_dset.n_fft, test_dset.hop_length)\n",
    "\n",
    "input_data = test_dset.whiten(log_spec)\n",
    "input_data = torch.from_numpy(input_data).unsqueeze(0).requires_grad_().to(device)\n",
    "one_hot = torch.from_numpy(np.eye(params['num_attractors'], params['num_attractors'])).unsqueeze(0).float().requires_grad_().to(device)\n",
    "\n",
    "#model.clusterer.n_clusters = 3\n",
    "with torch.no_grad():\n",
    "    masks, attractors, embedding = model(input_data, one_hots=one_hot)\n",
    "print(masks.shape)\n",
    "#masks = nn.functional.softmax(10*masks, dim=-1)\n",
    "#sources = nn.functional.softmax(5*sources, dim=-1)\n",
    "sources = masks.squeeze(0).cpu().data.numpy()\n",
    "print('Mixture')\n",
    "\n",
    "utilities.audio(mix, sr, ext='.wav')\n",
    "\n",
    "\n",
    "def fix_length(x):\n",
    "    return librosa.util.fix_length(x, len(x) + test_dset.n_fft // 2)\n",
    "\n",
    "def transform(x):\n",
    "    return np.abs(librosa.stft(fix_length(x), n_fft=test_dset.n_fft, hop_length=test_dset.hop_length))\n",
    "\n",
    "separations = []\n",
    "acc = 0\n",
    "\n",
    "res = mix\n",
    "\n",
    "for j in range(sources.shape[-1]):\n",
    "    mask = (sources[:, :, j].T) #/  (sources.sum(axis=-1).T ** 2.0)\n",
    "    #mask[mask<.5] = 0\n",
    "    print (mask.min(), mask.max())\n",
    "    isolated, mix = mask_mixture(mask, mix)\n",
    "    separations.append(isolated)\n",
    "    #print (test_dset.source_labels[j])\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(20*np.log(np.abs(librosa.stft(isolated)) + 1e-7), origin='lower', aspect='auto', cmap='magma')\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(mask, origin='lower', aspect='auto', cmap='magma')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    utilities.audio(isolated, sr, ext='.wav')\n",
    "    res -= isolated\n",
    "    \n",
    "    if j != 0:\n",
    "        acc += isolated\n",
    "    else:\n",
    "        utilities.audio(mix - isolated, sr, ext='.wav')\n",
    "utilities.audio(res, sr, ext='.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1/attractors[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attractor_mean = nn.functional.normalize(attractors.mean(dim=1, keepdim=True), dim=-1, p=2).detach().squeeze(0).cpu().numpy()\n",
    "#embedding_mean = nn.functional.normalize(embedding.mean(dim=1, keepdim=True), dim=-1, p=2).detach().squeeze(0).cpu().numpy()\n",
    "attractors_ = attractors[0].detach().squeeze(0).cpu().numpy()\n",
    "one_hot = torch.from_numpy(np.eye(params['num_attractors'], params['num_attractors'])).unsqueeze(0).float().requires_grad_().to(device)\n",
    "#generated_attractors = model.attractor_function(one_hot).detach().squeeze(0).cpu().numpy()\n",
    "embedding = model.embedding.detach().squeeze(0).cpu().numpy()\n",
    "weights = model.weights.detach().squeeze(0).cpu().numpy()\n",
    "#interpolated = attractors_.detach().cpu().numpy()\n",
    "fig = plt.figure(figsize=(30, 10))\n",
    "subplot = 121\n",
    "\n",
    "for j, num_dim in enumerate([2, 3]):\n",
    "    projection = '3d' if num_dim == 3 else None\n",
    "    threshold = .9 if num_dim == 3 else 0.1\n",
    "    ax = fig.add_subplot(subplot + j, projection=projection)\n",
    "    output_transform, ax = project_embeddings(np.vstack([embedding[weights>threshold], attractors_]), \n",
    "                                              t=0.0, \n",
    "                                              num_dimensions=num_dim, \n",
    "                                              fig=fig, ax=ax, bins=None, gridsize=200)\n",
    "    attractor_points = output_transform[-attractors_.shape[0]:]\n",
    "    labels = ['vocals', 'drums', 'bass', 'other'] #test_dset.classes\n",
    "    for i, x in enumerate(attractor_points):\n",
    "        if num_dim == 3:\n",
    "            if i >= len(labels):\n",
    "                labels.append('extra_%d' % i)\n",
    "            ax.text(attractor_points[i, 0], attractor_points[i, 1], attractor_points[i, 2], labels[i], size=20, zorder=1, color='w')\n",
    "        else:\n",
    "            if i >= len(labels):\n",
    "                labels.append('extra_%d' % i)\n",
    "            plt.annotate(labels[i], xy=x, size=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.generate_attractors(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding.norm(p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = embedding.reshape(-1, params['projection_size'], embedding.shape[-1])\n",
    "for i in range(x.shape[-1]):\n",
    "    #print (model.attractors[0][0][0][i], model.attractors[1][0][0][i])\n",
    "    plt.figure(figsize=(30, 4))\n",
    "    plt.imshow(x[:, :, i].T, aspect='auto', origin='lower', cmap='seismic', vmin=-1.0, vmax=1.0)\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.assignments.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attractors[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.split(attractors, [model.embedding_size, attractors.shape[-1] - model.embedding_size  - 1, 1], dim=-1)[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attractors = model.attractor_function(one_hot)\n",
    "attractors[:, : ,model.embedding_size:-1] **2, nn.functional.softmax(attractors[:, : , -1], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attractors[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.diag(s).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[1:] = 0\n",
    "x = np.dot(u*s, v)\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.imshow(x, aspect='auto', cmap='seismic')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vtv = np.dot(embedding.T, embedding)\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.imshow(vtv, aspect='auto', cmap='seismic')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "u, s, v = np.linalg.svd(vtv)\n",
    "plt.plot(s)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vtv = np.dot(embedding.T, embedding)\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.imshow(vtv, aspect='auto', cmap='seismic')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "u, s, v = np.linalg.svd(vtv)\n",
    "plt.plot(s)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loss import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.dot(attractors_, attractors_.T))\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = attractors[1]\n",
    "var\n",
    "#var.expand(-1, -1, model.embedding_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "labels = ['vocals', 'drums', 'bass', 'other', 'attractor', 'embedding']\n",
    "#print(attractors.shape, attractor_mean.shape,embedding_mean.shape )\n",
    "data = np.vstack([attractors_])\n",
    "print (data.shape)\n",
    "for i, attractor in enumerate(data):\n",
    "    plt.plot(attractor, label=labels[i])\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "plt.imshow(data)\n",
    "plt.yticks(range(data.shape[0]), labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attractors[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "#mm1/seetharaman/scaper_data/music_separation/validation/mixture/Music Delta - Reggae - mixture.wav\n",
    "#mix, sr = librosa.load('/mm1/seetharaman/scaper_data/music_separation/test/mixture/Al James - Schoolboy Facination - mixture.wav', duration=30, offset=30,  sr=16000)\n",
    "mix, sr = librosa.load('../audio/Hotel California Solo - The Eagles - Acoustic Guitar Cover-r3ebOxltJ1w.opus', duration=10, offset=10,  sr=44100)\n",
    "mix2, sr = librosa.load('../audio/He\\'s Back! Snare Solo - Flamnambulous--U.S. Army All-American Marching Band Audition-1MF8I-XgBq0.m4a', duration=10, offset=14,  sr=44100)\n",
    "mix3, sr = librosa.load('../audio/Bass Drum solo Battle-55ISUhExonc.m4a', duration=5, offset=14,  sr=44100)\n",
    "\n",
    "mix = mix2\n",
    "utilities.audio(mix, sr, ext='.wav')\n",
    "\n",
    "log_spec, stft = test_dset.transform(mix, test_dset.n_fft, test_dset.hop_length)\n",
    "print(log_spec.shape)\n",
    "\n",
    "input_data = log_spec\n",
    "input_data -= log_spec.mean()\n",
    "input_data /= log_spec.std() + 1e-7\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "plt.imshow(input_data.T, origin='lower', aspect='auto')\n",
    "plt.show()\n",
    "\n",
    "input_data = torch.from_numpy(input_data).unsqueeze(0).requires_grad_().to(device)\n",
    "one_hot = torch.from_numpy(np.eye(4, 4)).unsqueeze(0).float().requires_grad_().to(device)\n",
    "model.clusterer.n_clusters = 1\n",
    "model.num_attractors = 1\n",
    "model.clusterer.n_iterations = 10\n",
    "sources, attractors, embedding = model(input_data, one_hots=None) #[0]\n",
    "\n",
    "#attractors_ = nn.functional.normalize(attractors[:, 1, :] + attractors[:, 2, :], dim=-1, p=2).unsqueeze(0) #attractors[:, :, :].sum(keepdim=True, dim=1)\n",
    "attractors_ = model.embedding.mean(dim=1, keepdim=True)[0].unsqueeze(0)\n",
    "print (attractors_.shape)\n",
    "\n",
    "\n",
    "audio_file = '/mm1/seetharaman/scaper_data/music_separation/test/drums/Al James - Schoolboy Facination - drums.wav'\n",
    "#audio_file = '../audio/heartofgold.wav'\n",
    "mix, sr = librosa.load(audio_file, duration=30, offset=45,  sr=44100)\n",
    "\n",
    "log_spec, stft = test_dset.transform(mix, test_dset.n_fft, test_dset.hop_length)\n",
    "\n",
    "input_data = log_spec\n",
    "input_data -= log_spec.mean()\n",
    "input_data /= log_spec.std() + 1e-7\n",
    "\n",
    "input_data = torch.from_numpy(input_data).unsqueeze(0).requires_grad_().to(device)\n",
    "one_hot = torch.from_numpy(np.eye(4, 4)).unsqueeze(0).float().requires_grad_().to(device)\n",
    "\n",
    "model.clusterer.n_iterations = 0\n",
    "model.use_likelihoods = True\n",
    "sources, _, embedding = model(input_data, one_hot) #[0]\n",
    "num_batch, sequence_length, num_frequencies, embedding_size = sources.size()\n",
    "attractors = (attractors[0], attractors[1], attractors[2])\n",
    "sources, _, _ = model.project_embedding_onto_attractors(model.embedding, attractors, model.weights)\n",
    "sources = model.invert_projection(sources)\n",
    "sources = sources.clamp(0.0, 1.0)\n",
    "sources = sources.view(num_batch, sequence_length, num_frequencies, -1)\n",
    "sources = sources.squeeze(0).cpu().data.numpy()\n",
    "print('Mixture')\n",
    "\n",
    "utilities.audio(mix, sr, ext='.wav')\n",
    "def mask_mixture(source, mix):\n",
    "    n = len(mix)\n",
    "    mix = librosa.util.fix_length(mix, n + test_dset.n_fft // 2)\n",
    "    mix_stft = librosa.stft(mix, n_fft=test_dset.n_fft, hop_length=test_dset.hop_length)\n",
    "    masked_mix = mix_stft * mask\n",
    "    source = librosa.istft(masked_mix, hop_length=test_dset.hop_length, length=n)\n",
    "    return source\n",
    "\n",
    "for j in range(sources.shape[-1]):\n",
    "    mask = sources[:, :, j].T\n",
    "    isolated = mask_mixture(mask, mix)\n",
    "    print(mask.min(), mask.max())\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(20*np.log(np.abs(librosa.stft(isolated)) + 1e-7), origin='lower', aspect='auto')\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(mask, origin='lower', aspect='auto', vmin=0.0, vmax=1.0)\n",
    "    plt.show()\n",
    "    utilities.audio(isolated, sr, ext='.mp3')\n",
    "    utilities.audio(mix - isolated, sr, ext='.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attractors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(attractors.shape[0]):\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    plt.imshow(embedding[:, np.argmax(attractors_, axis=-1)[i]].reshape(-1, int(params['projection_size'])).T, aspect='auto', origin='lower')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
