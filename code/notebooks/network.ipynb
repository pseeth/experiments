{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'trainable'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-13f5dd0d2c48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m }\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_chimera_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'networks/chimera_config.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/pipeline/code/config/builders/build_chimera_config.py\u001b[0m in \u001b[0;36mbuild_chimera_config\u001b[0;34m(options)\u001b[0m\n\u001b[1;32m     21\u001b[0m                     \u001b[0;34m'num_mels'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_mels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                     \u001b[0;34m'direction'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'forward'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                     \u001b[0;34m'trainable'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'trainable'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m                     \u001b[0;34m'clamp'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 }\n",
      "\u001b[0;31mKeyError\u001b[0m: 'trainable'"
     ]
    }
   ],
   "source": [
    "from config.builders import build_chimera_config, build_dpcl_config, build_mi_config\n",
    "import json\n",
    "    \n",
    "args = {\n",
    "    'num_frequencies': 512,\n",
    "    'num_mels': -1,\n",
    "    'sample_rate': 44100,\n",
    "    'hidden_size': 300,\n",
    "    'bidirectional': True,\n",
    "    'num_layers': 4,\n",
    "    'embedding_size': 40,\n",
    "    'num_sources': 2,\n",
    "    'embedding_activation': ['tanh', 'unit_norm'],\n",
    "    'mask_activation': ['softmax']\n",
    "}\n",
    "\n",
    "config = build_chimera_config(args)\n",
    "with open('networks/chimera_config.json', 'w') as f:\n",
    "    json.dump(config, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(0.5240, grad_fn=<MulBackward>)]\n"
     ]
    }
   ],
   "source": [
    "from networks import SeparationModel\n",
    "from importlib import reload\n",
    "import trainer\n",
    "reload(trainer)\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "loss_tuples = [('dpcl', 'embedding', 1.0)]\n",
    "               #('mse', 'estimates', .5)]\n",
    "t = trainer.Trainer(output_folder='test/', \n",
    "        train_data=None, \n",
    "        validation_data=None, \n",
    "        model='networks/chimera_config.json',\n",
    "        loss_tuples=loss_tuples,\n",
    "        options={\n",
    "            'data_parallel': False,\n",
    "            'device': 'cpu'\n",
    "        })\n",
    "\n",
    "device = t.device\n",
    "model = t.module\n",
    "test_data = np.random.random((1, 100, 512))\n",
    "data = torch.from_numpy(test_data)\n",
    "data = {'log_spectrogram': data,\n",
    "         'magnitude_spectrogram': data}\n",
    "\n",
    "a0 = torch.randint(0, 2, (1, 100, 512))\n",
    "assignments = torch.stack([a0, 1-a0], dim=-1)\n",
    "weights = torch.rand((1, 100, 512))\n",
    "sources = torch.rand((1, 100, 512, 2))\n",
    "\n",
    "target = {'assignments': assignments, \n",
    "          'weights': weights,\n",
    "          'sources': sources}\n",
    "\n",
    "def prepare_data(data, device):\n",
    "    for k in data:\n",
    "        data[k] = data[k].float().to(device)\n",
    "    return data\n",
    "\n",
    "data = prepare_data(data, device)\n",
    "target = prepare_data(target, device)\n",
    "output = model(data)\n",
    "model.project_assignments(target['assignments'])\n",
    "\n",
    "loss = t.calculate_loss(output, target)\n",
    "sum(loss).backward()\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0439, 0.8477, 0.3971,  ..., 0.7753, 0.0547, 0.9786],\n",
       "         [0.3782, 0.4074, 0.5107,  ..., 0.6275, 0.2279, 0.5542],\n",
       "         [0.1048, 0.9835, 0.6676,  ..., 0.1544, 0.4599, 0.1064],\n",
       "         ...,\n",
       "         [0.5639, 0.0580, 0.0794,  ..., 0.6194, 0.2730, 0.7875],\n",
       "         [0.2483, 0.6578, 0.8597,  ..., 0.1383, 0.2640, 0.3030],\n",
       "         [0.0505, 0.2239, 0.3872,  ..., 0.6791, 0.7809, 0.4021]],\n",
       "\n",
       "        [[0.1705, 0.9387, 0.1563,  ..., 0.5904, 0.1079, 0.3421],\n",
       "         [0.3789, 0.4443, 0.0546,  ..., 0.0542, 0.8712, 0.7437],\n",
       "         [0.3697, 0.4379, 0.9856,  ..., 0.5885, 0.7984, 0.2812],\n",
       "         ...,\n",
       "         [0.7819, 0.0265, 0.5804,  ..., 0.9745, 0.9026, 0.0726],\n",
       "         [0.5433, 0.8991, 0.4388,  ..., 0.1924, 0.7758, 0.5085],\n",
       "         [0.0142, 0.5743, 0.0376,  ..., 0.0436, 0.0764, 0.0613]],\n",
       "\n",
       "        [[0.5929, 0.6472, 0.4401,  ..., 0.1365, 0.6311, 0.1979],\n",
       "         [0.8342, 0.2901, 0.7416,  ..., 0.9982, 0.4906, 0.9263],\n",
       "         [0.2811, 0.4352, 0.6739,  ..., 0.3135, 0.7237, 0.1419],\n",
       "         ...,\n",
       "         [0.5985, 0.3520, 0.1694,  ..., 0.0678, 0.8441, 0.7476],\n",
       "         [0.4303, 0.2524, 0.5979,  ..., 0.2152, 0.3548, 0.4953],\n",
       "         [0.8770, 0.2284, 0.6986,  ..., 0.6574, 0.9551, 0.2730]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.2223, 0.1474, 0.1154,  ..., 0.5166, 0.0984, 0.1442],\n",
       "         [0.3642, 0.7858, 0.3975,  ..., 0.4781, 0.8651, 0.3869],\n",
       "         [0.7696, 0.7255, 0.8973,  ..., 0.4266, 0.2431, 0.0115],\n",
       "         ...,\n",
       "         [0.5465, 0.4046, 0.6166,  ..., 0.1218, 0.0029, 0.5668],\n",
       "         [0.8041, 0.6993, 0.7429,  ..., 0.7316, 0.7166, 0.2832],\n",
       "         [0.0962, 0.6946, 0.8244,  ..., 0.0977, 0.4711, 0.9952]],\n",
       "\n",
       "        [[0.3965, 0.1445, 0.2862,  ..., 0.1001, 0.7186, 0.4453],\n",
       "         [0.1107, 0.3820, 0.5284,  ..., 0.4945, 0.5673, 0.7602],\n",
       "         [0.2546, 0.4317, 0.4271,  ..., 0.8907, 0.2574, 0.1559],\n",
       "         ...,\n",
       "         [0.5277, 0.3427, 0.2603,  ..., 0.4091, 0.0240, 0.8572],\n",
       "         [0.3566, 0.8684, 0.9359,  ..., 0.8654, 0.2365, 0.3108],\n",
       "         [0.9646, 0.6970, 0.7455,  ..., 0.8747, 0.4766, 0.6944]],\n",
       "\n",
       "        [[0.4264, 0.8583, 0.8566,  ..., 0.9637, 0.3127, 0.3521],\n",
       "         [0.5154, 0.1430, 0.0793,  ..., 0.7452, 0.2346, 0.7856],\n",
       "         [0.3653, 0.8148, 0.4276,  ..., 0.9133, 0.3684, 0.1065],\n",
       "         ...,\n",
       "         [0.4977, 0.6891, 0.4279,  ..., 0.8623, 0.6672, 0.2226],\n",
       "         [0.4125, 0.7973, 0.1343,  ..., 0.0050, 0.6961, 0.5702],\n",
       "         [0.4605, 0.8002, 0.1989,  ..., 0.4704, 0.0549, 0.6067]]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 2.4233e-01,  9.6219e-02,  1.6633e-01,  ..., -7.6923e-02,\n",
       "            5.7023e-02, -1.1445e-01],\n",
       "          [ 4.6402e-02,  1.7361e-01, -1.0590e-02,  ...,  1.3967e-01,\n",
       "            1.2356e-01,  2.1546e-01],\n",
       "          [-6.0788e-03, -1.0113e-01, -2.1805e-01,  ...,  3.4081e-02,\n",
       "            1.2679e-01, -2.2962e-01],\n",
       "          ...,\n",
       "          [-1.1002e-01, -2.1847e-01,  2.9475e-01,  ...,  2.6439e-01,\n",
       "            2.5229e-01,  8.9946e-02],\n",
       "          [ 1.7057e-01, -4.7226e-02,  4.2949e-02,  ..., -4.6590e-02,\n",
       "           -1.6946e-01, -1.4191e-01],\n",
       "          [-2.4431e-01, -2.4302e-01,  6.7314e-02,  ...,  5.3848e-02,\n",
       "           -1.2064e-01, -1.8532e-01]],\n",
       "\n",
       "         [[ 1.9860e-01,  1.1002e-01,  1.6472e-01,  ..., -1.6407e-02,\n",
       "            1.0030e-01, -1.5499e-01],\n",
       "          [ 5.1155e-02,  1.6975e-01, -1.5114e-02,  ...,  1.6391e-01,\n",
       "            9.3469e-02,  2.1145e-01],\n",
       "          [ 3.2065e-03, -9.7714e-02, -2.0795e-01,  ...,  2.8785e-02,\n",
       "            9.3135e-02, -1.9648e-01],\n",
       "          ...,\n",
       "          [-8.6883e-02, -2.1785e-01,  3.1869e-01,  ...,  2.8460e-01,\n",
       "            2.1753e-01,  7.8417e-02],\n",
       "          [ 1.4897e-01, -3.2816e-02,  6.5345e-02,  ..., -6.6075e-02,\n",
       "           -1.4231e-01, -1.9310e-01],\n",
       "          [-2.7529e-01, -1.9743e-01,  4.9551e-02,  ...,  2.8559e-02,\n",
       "           -1.1279e-01, -2.3704e-01]],\n",
       "\n",
       "         [[ 2.0037e-01,  1.4876e-01,  1.5978e-01,  ..., -6.6411e-02,\n",
       "            1.3923e-01, -1.1245e-01],\n",
       "          [ 6.4507e-02,  2.1831e-01, -5.0919e-02,  ...,  1.1358e-01,\n",
       "            1.2754e-01,  1.9176e-01],\n",
       "          [ 3.4135e-03, -1.3115e-01, -1.8827e-01,  ..., -3.7586e-02,\n",
       "            8.3577e-02, -1.6336e-01],\n",
       "          ...,\n",
       "          [-5.8885e-02, -2.1482e-01,  3.3448e-01,  ...,  3.0134e-01,\n",
       "            1.9821e-01,  1.0515e-01],\n",
       "          [ 1.5012e-01, -5.4299e-02, -8.0658e-03,  ..., -1.2007e-01,\n",
       "           -1.5471e-01, -2.3073e-01],\n",
       "          [-2.3835e-01, -2.2909e-01,  1.4797e-02,  ..., -2.5154e-03,\n",
       "           -1.0464e-01, -2.8686e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 7.9098e-02,  3.0845e-01, -2.7524e-02,  ..., -8.6450e-02,\n",
       "            1.4797e-01, -2.7170e-01],\n",
       "          [-8.7663e-02,  2.0482e-01,  1.1032e-01,  ...,  5.8492e-02,\n",
       "            4.7321e-02,  9.3470e-02],\n",
       "          [ 9.5609e-02, -6.2344e-02, -4.4956e-02,  ...,  1.7451e-01,\n",
       "            2.1794e-01,  1.1035e-02],\n",
       "          ...,\n",
       "          [-8.1178e-02, -1.7348e-01,  3.4326e-03,  ...,  2.7013e-01,\n",
       "           -8.4187e-04,  4.1647e-01],\n",
       "          [-3.5806e-02, -6.9958e-02, -1.8308e-01,  ..., -3.2943e-01,\n",
       "            1.3296e-01, -1.8869e-01],\n",
       "          [-1.0077e-01,  1.7774e-01, -9.9745e-02,  ...,  2.0611e-02,\n",
       "            1.5804e-01, -2.1092e-01]],\n",
       "\n",
       "         [[ 7.4143e-02,  2.9037e-01, -2.0178e-02,  ..., -4.0052e-02,\n",
       "            1.7059e-01, -2.8826e-01],\n",
       "          [-1.1545e-01,  1.7482e-01,  8.6532e-02,  ...,  7.2013e-02,\n",
       "            6.3634e-02,  8.6156e-02],\n",
       "          [ 4.6033e-02, -2.8527e-03, -3.6308e-02,  ...,  1.7237e-01,\n",
       "            2.2830e-01,  2.6279e-02],\n",
       "          ...,\n",
       "          [-9.3250e-02, -1.5103e-01,  4.8129e-02,  ...,  3.1435e-01,\n",
       "           -2.2985e-02,  4.1341e-01],\n",
       "          [-3.2538e-02, -4.5311e-02, -1.8227e-01,  ..., -3.2324e-01,\n",
       "            1.4836e-01, -1.3457e-01],\n",
       "          [-1.2947e-01,  1.3702e-01, -8.7794e-02,  ...,  1.6414e-02,\n",
       "            1.4158e-01, -2.2732e-01]],\n",
       "\n",
       "         [[ 2.7971e-02,  2.6579e-01, -5.5579e-02,  ..., -4.0800e-02,\n",
       "            2.0565e-01, -2.4670e-01],\n",
       "          [-5.2842e-02,  1.2187e-01,  1.0090e-01,  ...,  8.3436e-02,\n",
       "            8.6704e-02,  4.1468e-02],\n",
       "          [ 2.8269e-02, -4.1613e-02, -5.5928e-02,  ...,  1.6110e-01,\n",
       "            2.2390e-01,  5.5195e-02],\n",
       "          ...,\n",
       "          [-1.0571e-01, -1.1525e-01, -9.5573e-03,  ...,  3.2145e-01,\n",
       "            7.1650e-03,  4.1783e-01],\n",
       "          [-2.9584e-02, -8.2450e-02, -2.2994e-01,  ..., -3.5003e-01,\n",
       "            1.0570e-01, -1.4341e-01],\n",
       "          [-1.0886e-01,  1.3018e-01, -5.4783e-02,  ...,  2.6601e-02,\n",
       "            9.4586e-02, -1.8873e-01]]]], grad_fn=<DivBackward1>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classic_deep_clustering(embeddings, assignments, weights):\n",
    "    batch_size, num_points, embedding_size = embeddings.shape\n",
    "    weights = weights.view(batch_size, num_points, 1)\n",
    "    embeddings = weights.expand_as(embeddings) * embeddings\n",
    "    assignments = weights.expand_as(assignments) * assignments\n",
    "    # -- get normalization factor (normalize by sum over all applied weights)\n",
    "    # See (7) from ALTERNATIVE OBJECTIVE FUNCTIONS FOR DEEP CLUSTERING, Wang et al, 2017\n",
    "    # for how to apply weights.  Innermost square() because we're working with sqrt weights\n",
    "    # Then use (\\sum_{i} w_{ii})^2 = \\sum_{ij} w_i * w_j and sum over batches\n",
    "    count = torch.sum(torch.sum(weights**2, dim=1)**2)\n",
    "    \n",
    "    embeddings_transpose = embeddings.transpose(2, 1)\n",
    "    assignments_transpose = assignments.transpose(2, 1)\n",
    "    \n",
    "    vTv = torch.matmul(embeddings_transpose, embeddings)\n",
    "    vTy = torch.matmul(embeddings_transpose, assignments)\n",
    "    yTy = torch.matmul(assignments_transpose, assignments)\n",
    "    return (torch.sum(vTv**2) - 2*torch.sum(vTy**2) + torch.sum(yTy**2)) / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding size: 0001\t New loss: 0.4997, \tOld loss: 0.4997\n",
      "Embedding size: 0002\t New loss: 0.4015, \tOld loss: 0.4015\n",
      "Embedding size: 0004\t New loss: 0.3515, \tOld loss: 0.3515\n",
      "Embedding size: 0008\t New loss: 0.3321, \tOld loss: 0.3321\n",
      "Embedding size: 0016\t New loss: 0.3078, \tOld loss: 0.3078\n",
      "Embedding size: 0032\t New loss: 0.3092, \tOld loss: 0.3092\n",
      "Embedding size: 0064\t New loss: 0.3095, \tOld loss: 0.3095\n",
      "Embedding size: 0128\t New loss: 0.3102, \tOld loss: 0.3102\n",
      "Embedding size: 0256\t New loss: 0.3103, \tOld loss: 0.3103\n",
      "Embedding size: 0512\t New loss: 0.3052, \tOld loss: 0.3052\n",
      "Embedding size: 1024\t New loss: 0.2986, \tOld loss: 0.2986\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "batch_size=1\n",
    "num_points=100\n",
    "for e in [2**i for i in range(0, 11)]:\n",
    "    embedding_size=e\n",
    "    embedding = torch.rand(batch_size, num_points, embedding_size)\n",
    "    embedding = nn.functional.normalize(embedding, dim=-1, p=2)\n",
    "    weights = torch.rand(batch_size, num_points)\n",
    "    a0 = torch.randint(0,2, (batch_size, num_points))\n",
    "    assignments = torch.stack([a0, 1-a0], dim=-1)\n",
    "\n",
    "    output = {'embedding': embedding}\n",
    "    target = {'weights': weights,\n",
    "              'assignments': assignments}\n",
    "\n",
    "    loss = t.calculate_loss(output, target)\n",
    "    loss_cl = classic_deep_clustering(output['embedding'], target['assignments'], target['weights'])\n",
    "\n",
    "    print('Embedding size: {:0>4d}\\t New loss: {:.4f}, \\tOld loss: {:.4f}'.format(e, sum(loss).item(), loss_cl.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(305950.6250)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.0106)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_weights = ((weights ** 2).sum(dim=1)).sum()\n",
    "norm = ((embedding_size ** 2) * (num_weights ** 2)) - 2 * (embedding_size * (num_weights ** 2)) + (num_weights ** 2)\n",
    "\n",
    "print(norm)\n",
    "\n",
    "vTv = ((embedding.transpose(2, 1) @ embedding) ** 2)\n",
    "vTy = ((embedding.transpose(2, 1) @ assignments) ** 2)\n",
    "yTy = ((assignments.transpose(2, 1) @ assignments) ** 2)\n",
    "\n",
    "(vTv.sum() - 2 * vTy.sum() + yTy.sum()) / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[131.9500, 151.0961],\n",
       "          [ 99.2297, 141.4376],\n",
       "          [108.6486, 132.5084],\n",
       "          [139.3827, 155.2395],\n",
       "          [118.7430, 136.2694],\n",
       "          [130.8699, 145.6270],\n",
       "          [105.1004, 123.7130],\n",
       "          [ 77.9538, 135.6935],\n",
       "          [112.8176, 136.5007],\n",
       "          [ 73.8812, 133.4724],\n",
       "          [ 92.0670, 125.5312],\n",
       "          [ 90.9855,  98.6171],\n",
       "          [ 98.8411, 139.9132],\n",
       "          [126.3239, 119.3181],\n",
       "          [111.6611, 121.3125],\n",
       "          [119.6591,  99.3209]]]), tensor([[[2304.,    0.],\n",
       "          [   0., 2704.]]]), tensor([[[49.5241, 28.1220, 24.9829, 30.2371, 25.1409, 30.4873, 25.4457,\n",
       "           24.9004, 28.0923, 22.4296, 24.6680, 21.7190, 25.5763, 27.3789,\n",
       "           23.4485, 22.8465],\n",
       "          [28.1220, 40.7262, 22.3464, 25.1150, 24.0132, 25.2296, 19.4699,\n",
       "           21.4355, 22.2204, 18.6501, 19.1193, 16.3038, 21.2854, 22.0231,\n",
       "           18.9963, 22.0369],\n",
       "          [24.9829, 22.3464, 41.1049, 28.4609, 23.9456, 27.0004, 19.6646,\n",
       "           18.1279, 24.1623, 19.9386, 20.2513, 16.6141, 21.1948, 24.6786,\n",
       "           23.0014, 19.2022],\n",
       "          [30.2371, 25.1150, 28.4609, 54.4370, 28.9504, 31.4215, 27.9217,\n",
       "           21.5222, 27.3875, 24.6124, 25.6599, 21.9309, 28.7201, 25.4966,\n",
       "           27.6921, 24.1845],\n",
       "          [25.1409, 24.0132, 23.9456, 28.9504, 42.1201, 27.0319, 21.1705,\n",
       "           19.9729, 26.5216, 18.5301, 24.5916, 17.8601, 24.2005, 22.1308,\n",
       "           23.6642, 22.8706],\n",
       "          [30.4873, 25.2296, 27.0004, 31.4215, 27.0319, 46.6845, 24.1050,\n",
       "           24.5491, 25.7988, 22.2776, 22.3894, 19.8508, 25.0408, 25.6950,\n",
       "           26.4014, 23.5110],\n",
       "          [25.4457, 19.4699, 19.6646, 27.9217, 21.1705, 24.1050, 37.8945,\n",
       "           17.4870, 21.7967, 16.1217, 19.5693, 17.8042, 21.7654, 22.2543,\n",
       "           20.3520, 18.3664],\n",
       "          [24.9004, 21.4355, 18.1279, 21.5222, 19.9729, 24.5491, 17.4870,\n",
       "           31.8149, 20.8191, 16.6521, 16.7009, 14.8639, 20.2651, 21.7326,\n",
       "           17.2593, 17.6157],\n",
       "          [28.0923, 22.2204, 24.1623, 27.3875, 26.5216, 25.7988, 21.7967,\n",
       "           20.8191, 40.7705, 20.4311, 20.4762, 17.9066, 22.2234, 20.3760,\n",
       "           22.9870, 23.1558],\n",
       "          [22.4296, 18.6501, 19.9386, 24.6124, 18.5301, 22.2776, 16.1217,\n",
       "           16.6521, 20.4311, 30.7537, 16.4893, 14.9240, 15.8371, 19.5114,\n",
       "           19.7800, 16.5917],\n",
       "          [24.6680, 19.1193, 20.2513, 25.6599, 24.5916, 22.3894, 19.5693,\n",
       "           16.7009, 20.4762, 16.4893, 32.7303, 14.6609, 20.9314, 19.8384,\n",
       "           18.5753, 15.9824],\n",
       "          [21.7190, 16.3038, 16.6141, 21.9309, 17.8601, 19.8508, 17.8042,\n",
       "           14.8639, 17.9066, 14.9240, 14.6609, 30.0811, 15.8572, 20.0493,\n",
       "           18.5596, 16.0389],\n",
       "          [25.5763, 21.2854, 21.1948, 28.7201, 24.2005, 25.0408, 21.7654,\n",
       "           20.2651, 22.2234, 15.8371, 20.9314, 15.8572, 39.9145, 24.4597,\n",
       "           18.7056, 20.1056],\n",
       "          [27.3789, 22.0231, 24.6786, 25.4966, 22.1308, 25.6950, 22.2543,\n",
       "           21.7326, 20.3760, 19.5114, 19.8384, 20.0493, 24.4597, 42.0609,\n",
       "           21.2043, 19.2821],\n",
       "          [23.4485, 18.9963, 23.0014, 27.6921, 23.6642, 26.4014, 20.3520,\n",
       "           17.2593, 22.9870, 19.7800, 18.5753, 18.5596, 18.7056, 21.2043,\n",
       "           36.7986, 23.4439],\n",
       "          [22.8465, 22.0369, 19.2022, 24.1845, 22.8706, 23.5110, 18.3664,\n",
       "           17.6157, 23.1558, 16.5917, 15.9824, 16.0389, 20.1056, 19.2821,\n",
       "           23.4439, 32.1117]]]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vTy, yTy, vTv"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Old normalization: \n",
    "    norm = ((weights) ** 2).sum(dim=1) ** 2).sum()\n",
    "New normalization:\n",
    "    norm = (((weights) ** 2).sum(dim=1) ** 2).sum() * ((embedding_size + num_sources) ** 2)\n",
    "    \n",
    "Embedding: 0001\t New loss: 0.0404, \tOld loss: 0.3636\n",
    "Embedding: 0002\t New loss: 0.0218, \tOld loss: 0.3486\n",
    "Embedding: 0004\t New loss: 0.0189, \tOld loss: 0.6797\n",
    "Embedding: 0008\t New loss: 0.0282, \tOld loss: 2.8197\n",
    "Embedding: 0016\t New loss: 0.0407, \tOld loss: 13.1795\n",
    "Embedding: 0032\t New loss: 0.0512, \tOld loss: 59.2382\n",
    "Embedding: 0064\t New loss: 0.0571, \tOld loss: 248.6140\n",
    "Embedding: 0128\t New loss: 0.0599, \tOld loss: 1012.5200\n",
    "Embedding: 0256\t New loss: 0.0616, \tOld loss: 4098.5728\n",
    "Embedding: 0512\t New loss: 0.0624, \tOld loss: 16478.2500\n",
    "Embedding: 1024\t New loss: 0.0629, \tOld loss: 66198.8594\n",
    "\n",
    "Take 2\n",
    "    norm = ((((weights) ** 2) * (embedding_size + num_sources)).sum(dim=1) ** 2).sum()\n",
    "\n",
    "Embedding size: 0001\t New loss: 0.0405, \tOld loss: 0.3647\n",
    "Embedding size: 0002\t New loss: 0.0216, \tOld loss: 0.3452\n",
    "Embedding size: 0004\t New loss: 0.0188, \tOld loss: 0.6763\n",
    "Embedding size: 0008\t New loss: 0.0283, \tOld loss: 2.8313\n",
    "Embedding size: 0016\t New loss: 0.0416, \tOld loss: 13.4737\n",
    "Embedding size: 0032\t New loss: 0.0513, \tOld loss: 59.2936\n",
    "Embedding size: 0064\t New loss: 0.0565, \tOld loss: 246.3298\n",
    "Embedding size: 0128\t New loss: 0.0604, \tOld loss: 1020.3685\n",
    "Embedding size: 0256\t New loss: 0.0617, \tOld loss: 4105.6704\n",
    "Embedding size: 0512\t New loss: 0.0626, \tOld loss: 16528.9805\n",
    "Embedding size: 1024\t New loss: 0.0629, \tOld loss: 66199.3047"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers['mel_projection'].num_mels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainer import Trainer, LossFunctions\n",
    "\n",
    "\n",
    "t = Trainer(output_folder='test/', \n",
    "        train_data=None, \n",
    "        validation_data=None, \n",
    "        model='networks/dpcl_config.json',\n",
    "        loss_tuples=loss_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Trainer.calculate_loss of <trainer.Trainer object at 0x7ff20f646ac8>>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict = torch.load('networks/test.p')\n",
    "model = model_dict['model']\n",
    "model.load_state_dict(model_dict['state_dict'])\n",
    "model.eval()\n",
    "output = model(data)\n",
    "\n",
    "t.calculate_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepClusteringLoss()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LossFunctions['DPCL'].value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TEST'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'test'.upper()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
